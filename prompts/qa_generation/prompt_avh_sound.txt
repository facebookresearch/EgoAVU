OBJECTIVE:
Generate two sound-related question–answer pairs from an egocentric video caption.
The output must contain:
- One factual (correct) sound question
- One hallucinated (incorrect) sound question

INPUT:
You will be given an egocentric video narration describing:
- The person's visible actions
- Distinctive sounds (e.g., hissing, tapping, scraping)
- Objects present in the scene
- Temporal information about when events occur

INSTRUCTIONS:

1. Focus on Distinctive Sounds:
   - Include foreground sounds caused by human–object interactions
     (e.g., hissing, tapping, scraping).
   - You may also include background sounds
     (e.g., bird chirping, ambient noise).

2. Factual Question:
   - Generate ONE question about a sound that is explicitly mentioned
     in the narration.

3. Hallucinated Question:
   - Generate ONE question about a plausible sound that is NOT mentioned
     anywhere in the narration.

4. Answer Format:
   - Answers must be binary:
     "Yes" or "No"

OUTPUT FORMAT:
The output MUST be a valid JSON object with the following keys:

{
  "question": ["<question 1>", "<question 2>"],
  "question type": ["Factual", "Hallucinated"],
  "answers": ["Yes/No", "Yes/No"]
}

INPUT:
<input>

